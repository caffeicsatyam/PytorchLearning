{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pkp_OreKk1ew"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/100_Unique_QA_Dataset.csv\")"
      ],
      "metadata": {
        "id": "gGY7aHKloXtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zTTYCzbOofIw",
        "outputId": "a3d15ed6-e4c3-4bdb-eb37-1da004943ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e52be71-7281-4b29-80ee-bf7801960809\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e52be71-7281-4b29-80ee-bf7801960809')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e52be71-7281-4b29-80ee-bf7801960809 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e52be71-7281-4b29-80ee-bf7801960809');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-117121dc-4bc2-478d-bd5c-9dc531b3c1b9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-117121dc-4bc2-478d-bd5c-9dc531b3c1b9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-117121dc-4bc2-478d-bd5c-9dc531b3c1b9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"What is the currency of China?\",\n          \"What is the capital of Australia?\",\n          \"Who discovered electricity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"ChristopherColumbus\",\n          \"Paris\",\n          \"Christmas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TOkenize\n",
        "def Tokenize(text):\n",
        "  text = text.lower().replace('?','')\n",
        "  text = text.replace('!','')\n",
        "  text = text.replace(',','')\n",
        "  text = text.replace('.','')\n",
        "  return text.split()"
      ],
      "metadata": {
        "id": "V8iYizTWokM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {'<UK>':0}"
      ],
      "metadata": {
        "id": "LhvRQemJsbeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary\n",
        "def build_vacab(row):\n",
        "  tokenized_question = Tokenize(row['question'])\n",
        "  tokenized_answer = Tokenize(row['answer'])\n",
        "\n",
        "  merged_tokens = tokenized_question + tokenized_answer\n",
        "\n",
        "  for token in merged_tokens:\n",
        "    if token not in vocab:\n",
        "      vocab[token] = len(vocab)"
      ],
      "metadata": {
        "id": "S8HTLm0SqbQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vacab, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "DSNKcu-xrWCy",
        "outputId": "421d7e90-2c2b-44e7-fb99-e232b115baa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSD5wMoprk3y",
        "outputId": "1b4e506d-3cef-47f6-ad49-559a665e7114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UK>': 0,\n",
              " 'what': 1,\n",
              " 'is': 2,\n",
              " 'the': 3,\n",
              " 'capital': 4,\n",
              " 'of': 5,\n",
              " 'france': 6,\n",
              " 'paris': 7,\n",
              " 'germany': 8,\n",
              " 'berlin': 9,\n",
              " 'who': 10,\n",
              " 'wrote': 11,\n",
              " \"'to\": 12,\n",
              " 'kill': 13,\n",
              " 'a': 14,\n",
              " \"mockingbird'\": 15,\n",
              " 'harper-lee': 16,\n",
              " 'largest': 17,\n",
              " 'planet': 18,\n",
              " 'in': 19,\n",
              " 'our': 20,\n",
              " 'solar': 21,\n",
              " 'system': 22,\n",
              " 'jupiter': 23,\n",
              " 'boiling': 24,\n",
              " 'point': 25,\n",
              " 'water': 26,\n",
              " 'celsius': 27,\n",
              " '100': 28,\n",
              " 'painted': 29,\n",
              " 'mona': 30,\n",
              " 'lisa': 31,\n",
              " 'leonardo-da-vinci': 32,\n",
              " 'square': 33,\n",
              " 'root': 34,\n",
              " '64': 35,\n",
              " '8': 36,\n",
              " 'chemical': 37,\n",
              " 'symbol': 38,\n",
              " 'for': 39,\n",
              " 'gold': 40,\n",
              " 'au': 41,\n",
              " 'which': 42,\n",
              " 'year': 43,\n",
              " 'did': 44,\n",
              " 'world': 45,\n",
              " 'war': 46,\n",
              " 'ii': 47,\n",
              " 'end': 48,\n",
              " '1945': 49,\n",
              " 'longest': 50,\n",
              " 'river': 51,\n",
              " 'nile': 52,\n",
              " 'japan': 53,\n",
              " 'tokyo': 54,\n",
              " 'developed': 55,\n",
              " 'theory': 56,\n",
              " 'relativity': 57,\n",
              " 'albert-einstein': 58,\n",
              " 'freezing': 59,\n",
              " 'fahrenheit': 60,\n",
              " '32': 61,\n",
              " 'known': 62,\n",
              " 'as': 63,\n",
              " 'red': 64,\n",
              " 'mars': 65,\n",
              " 'author': 66,\n",
              " \"'1984'\": 67,\n",
              " 'george-orwell': 68,\n",
              " 'currency': 69,\n",
              " 'united': 70,\n",
              " 'kingdom': 71,\n",
              " 'pound': 72,\n",
              " 'india': 73,\n",
              " 'delhi': 74,\n",
              " 'discovered': 75,\n",
              " 'gravity': 76,\n",
              " 'newton': 77,\n",
              " 'how': 78,\n",
              " 'many': 79,\n",
              " 'continents': 80,\n",
              " 'are': 81,\n",
              " 'there': 82,\n",
              " 'on': 83,\n",
              " 'earth': 84,\n",
              " '7': 85,\n",
              " 'gas': 86,\n",
              " 'do': 87,\n",
              " 'plants': 88,\n",
              " 'use': 89,\n",
              " 'photosynthesis': 90,\n",
              " 'co2': 91,\n",
              " 'smallest': 92,\n",
              " 'prime': 93,\n",
              " 'number': 94,\n",
              " '2': 95,\n",
              " 'invented': 96,\n",
              " 'telephone': 97,\n",
              " 'alexander-graham-bell': 98,\n",
              " 'australia': 99,\n",
              " 'canberra': 100,\n",
              " 'ocean': 101,\n",
              " 'pacific-ocean': 102,\n",
              " 'speed': 103,\n",
              " 'light': 104,\n",
              " 'vacuum': 105,\n",
              " '299792458m/s': 106,\n",
              " 'language': 107,\n",
              " 'spoken': 108,\n",
              " 'brazil': 109,\n",
              " 'portuguese': 110,\n",
              " 'penicillin': 111,\n",
              " 'alexander-fleming': 112,\n",
              " 'canada': 113,\n",
              " 'ottawa': 114,\n",
              " 'mammal': 115,\n",
              " 'whale': 116,\n",
              " 'element': 117,\n",
              " 'has': 118,\n",
              " 'atomic': 119,\n",
              " '1': 120,\n",
              " 'hydrogen': 121,\n",
              " 'tallest': 122,\n",
              " 'mountain': 123,\n",
              " 'everest': 124,\n",
              " 'city': 125,\n",
              " 'big': 126,\n",
              " 'apple': 127,\n",
              " 'newyork': 128,\n",
              " 'planets': 129,\n",
              " \"'starry\": 130,\n",
              " \"night'\": 131,\n",
              " 'vangogh': 132,\n",
              " 'formula': 133,\n",
              " 'h2o': 134,\n",
              " 'italy': 135,\n",
              " 'rome': 136,\n",
              " 'country': 137,\n",
              " 'famous': 138,\n",
              " 'sushi': 139,\n",
              " 'was': 140,\n",
              " 'first': 141,\n",
              " 'person': 142,\n",
              " 'to': 143,\n",
              " 'step': 144,\n",
              " 'moon': 145,\n",
              " 'armstrong': 146,\n",
              " 'main': 147,\n",
              " 'ingredient': 148,\n",
              " 'guacamole': 149,\n",
              " 'avocado': 150,\n",
              " 'sides': 151,\n",
              " 'does': 152,\n",
              " 'hexagon': 153,\n",
              " 'have': 154,\n",
              " '6': 155,\n",
              " 'china': 156,\n",
              " 'yuan': 157,\n",
              " \"'pride\": 158,\n",
              " 'and': 159,\n",
              " \"prejudice'\": 160,\n",
              " 'jane-austen': 161,\n",
              " 'iron': 162,\n",
              " 'fe': 163,\n",
              " 'hardest': 164,\n",
              " 'natural': 165,\n",
              " 'substance': 166,\n",
              " 'diamond': 167,\n",
              " 'continent': 168,\n",
              " 'by': 169,\n",
              " 'area': 170,\n",
              " 'asia': 171,\n",
              " 'president': 172,\n",
              " 'states': 173,\n",
              " 'george-washington': 174,\n",
              " 'bird': 175,\n",
              " 'its': 176,\n",
              " 'ability': 177,\n",
              " 'mimic': 178,\n",
              " 'sounds': 179,\n",
              " 'parrot': 180,\n",
              " 'longest-running': 181,\n",
              " 'animated': 182,\n",
              " 'tv': 183,\n",
              " 'show': 184,\n",
              " 'simpsons': 185,\n",
              " 'vaticancity': 186,\n",
              " 'most': 187,\n",
              " 'moons': 188,\n",
              " 'saturn': 189,\n",
              " \"'romeo\": 190,\n",
              " \"juliet'\": 191,\n",
              " 'shakespeare': 192,\n",
              " \"earth's\": 193,\n",
              " 'atmosphere': 194,\n",
              " 'nitrogen': 195,\n",
              " 'bones': 196,\n",
              " 'adult': 197,\n",
              " 'human': 198,\n",
              " 'body': 199,\n",
              " '206': 200,\n",
              " 'metal': 201,\n",
              " 'liquid': 202,\n",
              " 'at': 203,\n",
              " 'room': 204,\n",
              " 'temperature': 205,\n",
              " 'mercury': 206,\n",
              " 'russia': 207,\n",
              " 'moscow': 208,\n",
              " 'electricity': 209,\n",
              " 'benjamin-franklin': 210,\n",
              " 'second-largest': 211,\n",
              " 'land': 212,\n",
              " 'color': 213,\n",
              " 'ripe': 214,\n",
              " 'banana': 215,\n",
              " 'yellow': 216,\n",
              " 'month': 217,\n",
              " '28': 218,\n",
              " 'days': 219,\n",
              " 'common': 220,\n",
              " 'february': 221,\n",
              " 'study': 222,\n",
              " 'living': 223,\n",
              " 'organisms': 224,\n",
              " 'called': 225,\n",
              " 'biology': 226,\n",
              " 'home': 227,\n",
              " 'great': 228,\n",
              " 'wall': 229,\n",
              " 'bees': 230,\n",
              " 'collect': 231,\n",
              " 'from': 232,\n",
              " 'flowers': 233,\n",
              " 'nectar': 234,\n",
              " 'opposite': 235,\n",
              " \"'day'\": 236,\n",
              " 'night': 237,\n",
              " 'south': 238,\n",
              " 'korea': 239,\n",
              " 'seoul': 240,\n",
              " 'bulb': 241,\n",
              " 'edison': 242,\n",
              " 'humans': 243,\n",
              " 'breathe': 244,\n",
              " 'survival': 245,\n",
              " 'oxygen': 246,\n",
              " '144': 247,\n",
              " '12': 248,\n",
              " 'pyramids': 249,\n",
              " 'giza': 250,\n",
              " 'egypt': 251,\n",
              " 'sea': 252,\n",
              " 'creature': 253,\n",
              " 'eight': 254,\n",
              " 'arms': 255,\n",
              " 'octopus': 256,\n",
              " 'holiday': 257,\n",
              " 'celebrated': 258,\n",
              " 'december': 259,\n",
              " '25': 260,\n",
              " 'christmas': 261,\n",
              " 'yen': 262,\n",
              " 'legs': 263,\n",
              " 'spider': 264,\n",
              " 'sport': 265,\n",
              " 'uses': 266,\n",
              " 'net': 267,\n",
              " 'ball': 268,\n",
              " 'hoop': 269,\n",
              " 'basketball': 270,\n",
              " 'kangaroos': 271,\n",
              " 'female': 272,\n",
              " 'minister': 273,\n",
              " 'uk': 274,\n",
              " 'margaretthatcher': 275,\n",
              " 'fastest': 276,\n",
              " 'animal': 277,\n",
              " 'cheetah': 278,\n",
              " 'periodic': 279,\n",
              " 'table': 280,\n",
              " 'spain': 281,\n",
              " 'madrid': 282,\n",
              " 'closest': 283,\n",
              " 'sun': 284,\n",
              " 'father': 285,\n",
              " 'computers': 286,\n",
              " 'charlesbabbage': 287,\n",
              " 'mexico': 288,\n",
              " 'mexicocity': 289,\n",
              " 'colors': 290,\n",
              " 'rainbow': 291,\n",
              " 'musical': 292,\n",
              " 'instrument': 293,\n",
              " 'black': 294,\n",
              " 'white': 295,\n",
              " 'keys': 296,\n",
              " 'piano': 297,\n",
              " 'americas': 298,\n",
              " '1492': 299,\n",
              " 'christophercolumbus': 300,\n",
              " 'disney': 301,\n",
              " 'character': 302,\n",
              " 'long': 303,\n",
              " 'nose': 304,\n",
              " 'grows': 305,\n",
              " 'it': 306,\n",
              " 'when': 307,\n",
              " 'lying': 308,\n",
              " 'pinocchio': 309,\n",
              " 'directed': 310,\n",
              " 'movie': 311,\n",
              " \"'titanic'\": 312,\n",
              " 'jamescameron': 313,\n",
              " 'superhero': 314,\n",
              " 'also': 315,\n",
              " 'dark': 316,\n",
              " 'knight': 317,\n",
              " 'batman': 318,\n",
              " 'brasilia': 319,\n",
              " 'fruit': 320,\n",
              " 'king': 321,\n",
              " 'fruits': 322,\n",
              " 'mango': 323,\n",
              " 'eiffel': 324,\n",
              " 'tower': 325}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert words to numerical values\n",
        "def text_to_indices(text, vocab):\n",
        "  indexed_text = []\n",
        "  for token in Tokenize(text):\n",
        "\n",
        "    if token in vocab:\n",
        "      indexed_text.append(vocab[token])\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UK>'])\n",
        "  return indexed_text\n"
      ],
      "metadata": {
        "id": "crZH40-LqdtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_indices(\"what is satyam\", vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2tsIu6gtWnv",
        "outputId": "386c0392-c118-4870-8c2c-a1ab9b99dbdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "EUYc5OBttdcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "\n",
        "  def __init__(self, df, vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
        "    numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
        "\n",
        "    return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
      ],
      "metadata": {
        "id": "oP3vEja9trNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QADataset(df, vocab)"
      ],
      "metadata": {
        "id": "kKQVsSlNvBdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "kGQDu7CXvHMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question , answer in dataloader:\n",
        "  print(question, answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6leoHcAVvVO1",
        "outputId": "fec28a2c-e761-47f6-eb7b-91d734bce340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n",
            "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
            "tensor([[  1,   2,   3,   4,   5, 238, 239]]) tensor([[240]])\n",
            "tensor([[ 42, 292, 293, 118, 294, 159, 295, 296]]) tensor([[297]])\n",
            "tensor([[ 42, 301, 302, 118,  14, 303, 304, 159, 305, 306, 307, 308]]) tensor([[309]])\n",
            "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
            "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
            "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
            "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
            "tensor([[ 42, 217, 118, 218, 219,  19,  14, 220,  43]]) tensor([[221]])\n",
            "tensor([[ 42, 201,   2,  14, 202, 203, 204, 205]]) tensor([[206]])\n",
            "tensor([[ 78,  79, 196,  81,  19,   3, 197, 198, 199]]) tensor([[200]])\n",
            "tensor([[ 78,  79, 151, 152,  14, 153, 154]]) tensor([[155]])\n",
            "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
            "tensor([[ 42,  18, 118,   3, 187, 188]]) tensor([[189]])\n",
            "tensor([[  1,   2,   3, 222,   5, 223, 224, 225]]) tensor([[226]])\n",
            "tensor([[ 10,  75,   3, 298,  19, 299]]) tensor([[300]])\n",
            "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
            "tensor([[  1,   2,   3, 213,   5,  14, 214, 215]]) tensor([[216]])\n",
            "tensor([[ 42,  86,  87, 243, 244,  19,  39, 245]]) tensor([[246]])\n",
            "tensor([[ 42, 137,   2, 138,  39, 176, 271]]) tensor([[99]])\n",
            "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
            "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
            "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
            "tensor([[ 42, 252, 253, 118, 254, 255]]) tensor([[256]])\n",
            "tensor([[ 10, 140,   3, 141, 272,  93, 273,   5,   3, 274]]) tensor([[275]])\n",
            "tensor([[ 10,  11, 190, 159, 191]]) tensor([[192]])\n",
            "tensor([[  1,   2,   3, 141, 117,  83,   3, 279, 280]]) tensor([[121]])\n",
            "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
            "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
            "tensor([[ 10,   2,  62,  63,   3, 285,   5, 286]]) tensor([[287]])\n",
            "tensor([[  1,   2,   3, 147, 148,  19, 149]]) tensor([[150]])\n",
            "tensor([[  1,   2,   3, 235,   5, 236]]) tensor([[237]])\n",
            "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
            "tensor([[ 42,   2,   3, 276, 212, 277]]) tensor([[278]])\n",
            "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
            "tensor([[  1,   2,   3,   4,   5, 281]]) tensor([[282]])\n",
            "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
            "tensor([[ 42, 257,   2, 258,  83, 259, 260]]) tensor([[261]])\n",
            "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
            "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
            "tensor([[ 10,  11, 158, 159, 160]]) tensor([[161]])\n",
            "tensor([[ 42, 137, 118,   3, 249,   5, 250]]) tensor([[251]])\n",
            "tensor([[ 42,  18,   2,   3, 283, 143,   3, 284]]) tensor([[206]])\n",
            "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
            "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
            "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
            "tensor([[  1,   2,   3,  69,   5, 156]]) tensor([[157]])\n",
            "tensor([[ 10, 140,   3, 141, 142, 143, 144,  83,   3, 145]]) tensor([[146]])\n",
            "tensor([[  1,   2,   3,   4,   5, 288]]) tensor([[289]])\n",
            "tensor([[10, 75, 76]]) tensor([[77]])\n",
            "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
            "tensor([[ 10, 310,   3, 311, 312]]) tensor([[313]])\n",
            "tensor([[ 10,  75, 209]]) tensor([[210]])\n",
            "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
            "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[186]])\n",
            "tensor([[ 42, 175,   2,  62,  39, 176, 177, 143, 178, 179]]) tensor([[180]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n",
            "tensor([[ 42, 265, 266,  14, 267, 268, 159, 269]]) tensor([[270]])\n",
            "tensor([[  1,   2,   3, 164, 165, 166,  83,  84]]) tensor([[167]])\n",
            "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
            "tensor([[ 42, 168,   2,   3,  17, 169, 170]]) tensor([[171]])\n",
            "tensor([[  1,   2,   3, 147,  86,  19, 193, 194]]) tensor([[195]])\n",
            "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
            "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
            "tensor([[  1,   2,   3,  33,  34,   5, 247]]) tensor([[248]])\n",
            "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
            "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
            "tensor([[ 42,   2,   3, 211, 137, 169, 212, 170]]) tensor([[113]])\n",
            "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
            "tensor([[ 42, 320,   2,  62,  63,   3, 321,   5, 322]]) tensor([[323]])\n",
            "tensor([[ 10, 140,   3, 141, 172,   5,   3,  70, 173]]) tensor([[174]])\n",
            "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
            "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
            "tensor([[ 42, 314,   2, 315,  62,  63,   3, 316, 317]]) tensor([[318]])\n",
            "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[319]])\n",
            "tensor([[ 78,  79, 263, 152,  14, 264, 154]]) tensor([[36]])\n",
            "tensor([[ 10,  96,   3, 104, 241]]) tensor([[242]])\n",
            "tensor([[  1,  87, 230, 231, 232, 233]]) tensor([[234]])\n",
            "tensor([[ 78,  79, 290,  81,  19,  14, 291]]) tensor([[85]])\n",
            "tensor([[ 42, 137,   2,  62,  39,   3, 324, 325]]) tensor([[6]])\n",
            "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[262]])\n",
            "tensor([[  1,   2,   3, 181, 182, 183, 184]]) tensor([[185]])\n",
            "tensor([[ 42, 137,   2, 227, 143,   3, 228, 229]]) tensor([[156]])\n",
            "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
            "tensor([[  1,   2,   3,   4,   5, 207]]) tensor([[208]])\n",
            "tensor([[  1,   2,   3,  37,  38,  39, 162]]) tensor([[163]])\n",
            "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "XYYux30Ovevj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "    # Corrected: Added batch_first=True for consistency with embedding output\n",
        "    self.rnn = nn.RNN(50, 60, batch_first=True)\n",
        "    # Corrected: in_features should be 60 to match rnn hidden_size\n",
        "    self.fc = nn.Linear(60, vocab_size)\n",
        "\n",
        "\n",
        "  def forward(self, question):\n",
        "    embedded_question = self.embedding(question) # shape: (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "    # The rnn will now accept batch-first input\n",
        "    # output_rnn: (batch_size, seq_len, hidden_size) - all hidden states\n",
        "    # final: (num_layers * num_directions, batch_size, hidden_size) - final hidden state\n",
        "    output_rnn, final = self.rnn(embedded_question)\n",
        "\n",
        "    # Corrected: Squeeze the first dimension of final to get (batch_size, hidden_size)\n",
        "    output = self.fc(final.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "KzB4v81txUEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "Unh-RepCzYZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNN(len(vocab))"
      ],
      "metadata": {
        "id": "y5TMHzpSzhyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "6wK72skPzpVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for question, answer in dataloader:\n",
        "        answer = answer.squeeze(1).long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(question)\n",
        "\n",
        "        loss = criterion(output, answer)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch + 1}, Loss = {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXfZ_XORzsVT",
        "outputId": "b78c8630-16bb-47f6-da72-e337f0e6e2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss = 0.0012\n",
            "Epoch 2, Loss = 0.0011\n",
            "Epoch 3, Loss = 0.0010\n",
            "Epoch 4, Loss = 0.0009\n",
            "Epoch 5, Loss = 0.0010\n",
            "Epoch 6, Loss = 0.0009\n",
            "Epoch 7, Loss = 0.0009\n",
            "Epoch 8, Loss = 0.0009\n",
            "Epoch 9, Loss = 0.0008\n",
            "Epoch 10, Loss = 0.0008\n",
            "Epoch 11, Loss = 0.0008\n",
            "Epoch 12, Loss = 0.0007\n",
            "Epoch 13, Loss = 0.0007\n",
            "Epoch 14, Loss = 0.0007\n",
            "Epoch 15, Loss = 0.0006\n",
            "Epoch 16, Loss = 0.0006\n",
            "Epoch 17, Loss = 0.0006\n",
            "Epoch 18, Loss = 0.0006\n",
            "Epoch 19, Loss = 0.0005\n",
            "Epoch 20, Loss = 0.0005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, question, threshold=0.5):\n",
        "\n",
        "  # convert question to numbers\n",
        "  numerical_question = text_to_indices(question, vocab)\n",
        "\n",
        "  # tensor\n",
        "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
        "\n",
        "  # send to model\n",
        "  output = model(question_tensor)\n",
        "\n",
        "  # convert logits to probs\n",
        "  probs = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "  # find index of max prob\n",
        "  value, index = torch.max(probs, dim=1)\n",
        "\n",
        "  if value < threshold:\n",
        "    print(\"I don't know\")\n",
        "\n",
        "  print(list(vocab.keys())[index])"
      ],
      "metadata": {
        "id": "ipqlOKZ00PY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, \"What is the largest planet in our solar system?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOuKiv_k2A46",
        "outputId": "c4374dfa-37db-47c6-b0a2-b7ab463c4a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jupiter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(vocab.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kivwoUUP4aF8",
        "outputId": "95388127-33e8-4685-dcf9-a45b704d486b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<UK>',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'capital',\n",
              " 'of',\n",
              " 'france',\n",
              " 'paris',\n",
              " 'germany',\n",
              " 'berlin',\n",
              " 'who',\n",
              " 'wrote',\n",
              " \"'to\",\n",
              " 'kill',\n",
              " 'a',\n",
              " \"mockingbird'\",\n",
              " 'harper-lee',\n",
              " 'largest',\n",
              " 'planet',\n",
              " 'in',\n",
              " 'our',\n",
              " 'solar',\n",
              " 'system',\n",
              " 'jupiter',\n",
              " 'boiling',\n",
              " 'point',\n",
              " 'water',\n",
              " 'celsius',\n",
              " '100',\n",
              " 'painted',\n",
              " 'mona',\n",
              " 'lisa',\n",
              " 'leonardo-da-vinci',\n",
              " 'square',\n",
              " 'root',\n",
              " '64',\n",
              " '8',\n",
              " 'chemical',\n",
              " 'symbol',\n",
              " 'for',\n",
              " 'gold',\n",
              " 'au',\n",
              " 'which',\n",
              " 'year',\n",
              " 'did',\n",
              " 'world',\n",
              " 'war',\n",
              " 'ii',\n",
              " 'end',\n",
              " '1945',\n",
              " 'longest',\n",
              " 'river',\n",
              " 'nile',\n",
              " 'japan',\n",
              " 'tokyo',\n",
              " 'developed',\n",
              " 'theory',\n",
              " 'relativity',\n",
              " 'albert-einstein',\n",
              " 'freezing',\n",
              " 'fahrenheit',\n",
              " '32',\n",
              " 'known',\n",
              " 'as',\n",
              " 'red',\n",
              " 'mars',\n",
              " 'author',\n",
              " \"'1984'\",\n",
              " 'george-orwell',\n",
              " 'currency',\n",
              " 'united',\n",
              " 'kingdom',\n",
              " 'pound',\n",
              " 'india',\n",
              " 'delhi',\n",
              " 'discovered',\n",
              " 'gravity',\n",
              " 'newton',\n",
              " 'how',\n",
              " 'many',\n",
              " 'continents',\n",
              " 'are',\n",
              " 'there',\n",
              " 'on',\n",
              " 'earth',\n",
              " '7',\n",
              " 'gas',\n",
              " 'do',\n",
              " 'plants',\n",
              " 'use',\n",
              " 'photosynthesis',\n",
              " 'co2',\n",
              " 'smallest',\n",
              " 'prime',\n",
              " 'number',\n",
              " '2',\n",
              " 'invented',\n",
              " 'telephone',\n",
              " 'alexander-graham-bell',\n",
              " 'australia',\n",
              " 'canberra',\n",
              " 'ocean',\n",
              " 'pacific-ocean',\n",
              " 'speed',\n",
              " 'light',\n",
              " 'vacuum',\n",
              " '299792458m/s',\n",
              " 'language',\n",
              " 'spoken',\n",
              " 'brazil',\n",
              " 'portuguese',\n",
              " 'penicillin',\n",
              " 'alexander-fleming',\n",
              " 'canada',\n",
              " 'ottawa',\n",
              " 'mammal',\n",
              " 'whale',\n",
              " 'element',\n",
              " 'has',\n",
              " 'atomic',\n",
              " '1',\n",
              " 'hydrogen',\n",
              " 'tallest',\n",
              " 'mountain',\n",
              " 'everest',\n",
              " 'city',\n",
              " 'big',\n",
              " 'apple',\n",
              " 'newyork',\n",
              " 'planets',\n",
              " \"'starry\",\n",
              " \"night'\",\n",
              " 'vangogh',\n",
              " 'formula',\n",
              " 'h2o',\n",
              " 'italy',\n",
              " 'rome',\n",
              " 'country',\n",
              " 'famous',\n",
              " 'sushi',\n",
              " 'was',\n",
              " 'first',\n",
              " 'person',\n",
              " 'to',\n",
              " 'step',\n",
              " 'moon',\n",
              " 'armstrong',\n",
              " 'main',\n",
              " 'ingredient',\n",
              " 'guacamole',\n",
              " 'avocado',\n",
              " 'sides',\n",
              " 'does',\n",
              " 'hexagon',\n",
              " 'have',\n",
              " '6',\n",
              " 'china',\n",
              " 'yuan',\n",
              " \"'pride\",\n",
              " 'and',\n",
              " \"prejudice'\",\n",
              " 'jane-austen',\n",
              " 'iron',\n",
              " 'fe',\n",
              " 'hardest',\n",
              " 'natural',\n",
              " 'substance',\n",
              " 'diamond',\n",
              " 'continent',\n",
              " 'by',\n",
              " 'area',\n",
              " 'asia',\n",
              " 'president',\n",
              " 'states',\n",
              " 'george-washington',\n",
              " 'bird',\n",
              " 'its',\n",
              " 'ability',\n",
              " 'mimic',\n",
              " 'sounds',\n",
              " 'parrot',\n",
              " 'longest-running',\n",
              " 'animated',\n",
              " 'tv',\n",
              " 'show',\n",
              " 'simpsons',\n",
              " 'vaticancity',\n",
              " 'most',\n",
              " 'moons',\n",
              " 'saturn',\n",
              " \"'romeo\",\n",
              " \"juliet'\",\n",
              " 'shakespeare',\n",
              " \"earth's\",\n",
              " 'atmosphere',\n",
              " 'nitrogen',\n",
              " 'bones',\n",
              " 'adult',\n",
              " 'human',\n",
              " 'body',\n",
              " '206',\n",
              " 'metal',\n",
              " 'liquid',\n",
              " 'at',\n",
              " 'room',\n",
              " 'temperature',\n",
              " 'mercury',\n",
              " 'russia',\n",
              " 'moscow',\n",
              " 'electricity',\n",
              " 'benjamin-franklin',\n",
              " 'second-largest',\n",
              " 'land',\n",
              " 'color',\n",
              " 'ripe',\n",
              " 'banana',\n",
              " 'yellow',\n",
              " 'month',\n",
              " '28',\n",
              " 'days',\n",
              " 'common',\n",
              " 'february',\n",
              " 'study',\n",
              " 'living',\n",
              " 'organisms',\n",
              " 'called',\n",
              " 'biology',\n",
              " 'home',\n",
              " 'great',\n",
              " 'wall',\n",
              " 'bees',\n",
              " 'collect',\n",
              " 'from',\n",
              " 'flowers',\n",
              " 'nectar',\n",
              " 'opposite',\n",
              " \"'day'\",\n",
              " 'night',\n",
              " 'south',\n",
              " 'korea',\n",
              " 'seoul',\n",
              " 'bulb',\n",
              " 'edison',\n",
              " 'humans',\n",
              " 'breathe',\n",
              " 'survival',\n",
              " 'oxygen',\n",
              " '144',\n",
              " '12',\n",
              " 'pyramids',\n",
              " 'giza',\n",
              " 'egypt',\n",
              " 'sea',\n",
              " 'creature',\n",
              " 'eight',\n",
              " 'arms',\n",
              " 'octopus',\n",
              " 'holiday',\n",
              " 'celebrated',\n",
              " 'december',\n",
              " '25',\n",
              " 'christmas',\n",
              " 'yen',\n",
              " 'legs',\n",
              " 'spider',\n",
              " 'sport',\n",
              " 'uses',\n",
              " 'net',\n",
              " 'ball',\n",
              " 'hoop',\n",
              " 'basketball',\n",
              " 'kangaroos',\n",
              " 'female',\n",
              " 'minister',\n",
              " 'uk',\n",
              " 'margaretthatcher',\n",
              " 'fastest',\n",
              " 'animal',\n",
              " 'cheetah',\n",
              " 'periodic',\n",
              " 'table',\n",
              " 'spain',\n",
              " 'madrid',\n",
              " 'closest',\n",
              " 'sun',\n",
              " 'father',\n",
              " 'computers',\n",
              " 'charlesbabbage',\n",
              " 'mexico',\n",
              " 'mexicocity',\n",
              " 'colors',\n",
              " 'rainbow',\n",
              " 'musical',\n",
              " 'instrument',\n",
              " 'black',\n",
              " 'white',\n",
              " 'keys',\n",
              " 'piano',\n",
              " 'americas',\n",
              " '1492',\n",
              " 'christophercolumbus',\n",
              " 'disney',\n",
              " 'character',\n",
              " 'long',\n",
              " 'nose',\n",
              " 'grows',\n",
              " 'it',\n",
              " 'when',\n",
              " 'lying',\n",
              " 'pinocchio',\n",
              " 'directed',\n",
              " 'movie',\n",
              " \"'titanic'\",\n",
              " 'jamescameron',\n",
              " 'superhero',\n",
              " 'also',\n",
              " 'dark',\n",
              " 'knight',\n",
              " 'batman',\n",
              " 'brasilia',\n",
              " 'fruit',\n",
              " 'king',\n",
              " 'fruits',\n",
              " 'mango',\n",
              " 'eiffel',\n",
              " 'tower']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Yo9Vcqs_TfM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}